{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5e5551",
   "metadata": {},
   "source": [
    "# Sales Forecasting Project â€” Colab-ready Notebook\n",
    "\n",
    "**Purpose:** Predict future sales using synthetic time-series data. This notebook trains ARIMA, Prophet, and LSTM models and compares forecasts.\n",
    "\n",
    "**Notes:**\n",
    "- Uses built-in synthetic dataset (daily sales + promotions) so it runs without uploads.\n",
    "- Long-running cells (LSTM training) are kept modest so it finishes comfortably in Colab.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run this first). In Colab this may take a few minutes.\n",
    "!pip install -q numpy pandas matplotlib seaborn statsmodels prophet tensorflow scikit-learn nbformat\n",
    "# fbprophet fallback isn't installed here by default; 'prophet' package is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de65290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and folder setup\n",
    "import os, warnings, math, pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Prophet import (will use 'prophet' package)\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except Exception as e:\n",
    "    Prophet = None\n",
    "    print('Prophet not available:', e)\n",
    "\n",
    "# TensorFlow/Keras\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "except Exception as e:\n",
    "    tf = None\n",
    "    print('TensorFlow not available:', e)\n",
    "\n",
    "# Create output folders\n",
    "os.makedirs('/content/outputs', exist_ok=True)\n",
    "os.makedirs('/content/models', exist_ok=True)\n",
    "print('Folders created: /content/outputs and /content/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74029a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic daily sales data (2020-01-01 to 2023-12-31)\n",
    "rng = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
    "np.random.seed(42)\n",
    "base = 200 + 0.05 * np.arange(len(rng))  # slight trend\n",
    "seasonal = 20 * np.sin(2 * np.pi * rng.dayofyear / 365.25)  # yearly seasonality\n",
    "dow = 10 * ((rng.dayofweek >=5).astype(int))  # weekend uplift\n",
    "noise = np.random.normal(0, 8, len(rng))\n",
    "# promotions: random weeks with +50 boost\n",
    "promo = np.zeros(len(rng), dtype=int)\n",
    "promo_weeks = np.random.choice(np.arange(len(rng)//7), size=20, replace=False)\n",
    "for w in promo_weeks:\n",
    "    start = w*7\n",
    "    promo[start:start+7] = 1\n",
    "promo_effect = promo * 50\n",
    "sales = base + seasonal + dow + promo_effect + noise\n",
    "df = pd.DataFrame({'date': rng, 'sales': sales, 'promo': promo}).set_index('date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a834af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick EDA + save main plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df.index, df['sales'])\n",
    "plt.title('Sales over time (synthetic)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/outputs/sales_time_series.png')\n",
    "plt.show()\n",
    "\n",
    "# STL decomposition\n",
    "stl = STL(df['sales'], period=365)\n",
    "res = stl.fit()\n",
    "fig = res.plot()\n",
    "plt.suptitle('STL Decomposition')\n",
    "plt.savefig('/content/outputs/stl_decomposition.png')\n",
    "plt.show()\n",
    "\n",
    "# Augmented Dickey-Fuller\n",
    "adf_result = adfuller(df['sales'])\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6002f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (last 90 days for test)\n",
    "forecast_horizon = 90\n",
    "train = df[:-forecast_horizon].copy()\n",
    "test = df[-forecast_horizon:].copy()\n",
    "print('Train:', train.index.min().date(), 'to', train.index.max().date())\n",
    "print('Test:', test.index.min().date(), 'to', test.index.max().date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e948b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "def evaluate(y_true, y_pred, label='model'):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print(f\"{label} -> MAE: {mae:.3f}, RMSE: {rmse:.3f}, MAPE: {mape:.2f}%\")\n",
    "    return {'mae': mae, 'rmse': rmse, 'mape': mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA with weekly seasonality & promo as exogenous var\n",
    "p,d,q = 5,1,2\n",
    "seasonal_order = (1,1,1,7)\n",
    "exog_train = train[['promo']]\n",
    "exog_test = test[['promo']]\n",
    "arima_model = ARIMA(train['sales'], order=(p,d,q), seasonal_order=seasonal_order, exog=exog_train)\n",
    "arima_res = arima_model.fit()\n",
    "print(arima_res.summary())\n",
    "\n",
    "arima_fore = arima_res.predict(start=test.index[0], end=test.index[-1], exog=exog_test)\n",
    "evaluate(test['sales'], arima_fore, label='ARIMA')\n",
    "\n",
    "# Save plot and model\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(train.index[-180:], train['sales'][-180:], label='train (last 180 days)')\n",
    "plt.plot(test.index, test['sales'], label='actual')\n",
    "plt.plot(arima_fore.index, arima_fore, label='arima_pred')\n",
    "plt.legend()\n",
    "plt.title('ARIMA Forecast vs Actual')\n",
    "plt.savefig('/content/outputs/arima_forecast.png')\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('/content/models/arima_model.pkl','wb') as f:\n",
    "    pickle.dump(arima_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet model (if available)\n",
    "prophet_pred = None\n",
    "if Prophet is None:\n",
    "    print('Prophet not installed; skipping Prophet model.')\n",
    "else:\n",
    "    prophet_df = train[['sales']].reset_index().rename(columns={'date':'ds','sales':'y'})\n",
    "    prophet_df['promo'] = train['promo'].values\n",
    "    m = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)\n",
    "    m.add_regressor('promo')\n",
    "    m.fit(prophet_df)\n",
    "    future = m.make_future_dataframe(periods=forecast_horizon)\n",
    "    future = future.set_index('ds')\n",
    "    future['promo'] = 0\n",
    "    future.loc[train.index,'promo'] = train['promo']\n",
    "    future.loc[test.index,'promo'] = test['promo']\n",
    "    future = future.reset_index()\n",
    "    fcst = m.predict(future)\n",
    "    prophet_pred = fcst.set_index('ds')['yhat'][-forecast_horizon:]\n",
    "    evaluate(test['sales'], prophet_pred, label='Prophet')\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(test.index, test['sales'], label='actual')\n",
    "    plt.plot(prophet_pred.index, prophet_pred, label='prophet_pred')\n",
    "    plt.legend()\n",
    "    plt.title('Prophet Forecast vs Actual')\n",
    "    plt.savefig('/content/outputs/prophet_forecast.png')\n",
    "    plt.show()\n",
    "    import pickle\n",
    "    with open('/content/models/prophet_model.pkl','wb') as f:\n",
    "        pickle.dump(m, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM forecasting (simple sliding-window). Smaller model/epochs for Colab runtime.\n",
    "lstm_pred_series = None\n",
    "if tf is None:\n",
    "    print('TensorFlow not installed; skipping LSTM.')\n",
    "else:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    data_lstm = train[['sales','promo']].copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(data_lstm)\n",
    "    lookback = 30\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(scaled)):\n",
    "        X.append(scaled[i-lookback:i])\n",
    "        y.append(scaled[i,0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    split = int(0.9 * len(X))\n",
    "    X_train_l, X_val_l = X[:split], X[split:]\n",
    "    y_train_l, y_val_l = y[:split], y[split:]\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(lookback, X.shape[2])),\n",
    "        layers.LSTM(64, return_sequences=False),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # Train for few epochs to keep runtime reasonable\n",
    "    history = model.fit(X_train_l, y_train_l, validation_data=(X_val_l, y_val_l), epochs=8, batch_size=32)\n",
    "\n",
    "    # Rolling forecast for test period\n",
    "    last_seq = scaled[-lookback:]\n",
    "    preds = []\n",
    "    for i in range(forecast_horizon):\n",
    "        x_in = last_seq.reshape(1, lookback, X.shape[2])\n",
    "        p = model.predict(x_in)[0,0]\n",
    "        preds.append(p)\n",
    "        promo_val = test['promo'].iloc[i]\n",
    "        promo_scaled = scaler.transform(np.array([[0, promo_val]]))[0,1]\n",
    "        next_scaled = np.array([p, promo_scaled])\n",
    "        last_seq = np.vstack([last_seq[1:], next_scaled])\n",
    "    # convert scaled sales preds back to original\n",
    "    sales_min, sales_max = scaler.data_min_[0], scaler.data_max_[0]\n",
    "    preds_unscaled = np.array(preds) * (sales_max - sales_min) + sales_min\n",
    "    lstm_pred_series = pd.Series(preds_unscaled, index=test.index)\n",
    "    evaluate(test['sales'], lstm_pred_series, label='LSTM')\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(test.index, test['sales'], label='actual')\n",
    "    plt.plot(lstm_pred_series.index, lstm_pred_series, label='lstm_pred')\n",
    "    plt.legend()\n",
    "    plt.title('LSTM Forecast vs Actual')\n",
    "    plt.savefig('/content/outputs/lstm_forecast.png')\n",
    "    plt.show()\n",
    "    model.save('/content/models/lstm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed51190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble (average of available model predictions)\n",
    "preds = pd.DataFrame({'actual': test['sales']})\n",
    "preds['arima'] = arima_fore\n",
    "if 'prophet_pred' in globals() and prophet_pred is not None:\n",
    "    preds['prophet'] = prophet_pred\n",
    "if 'lstm_pred_series' in globals() and lstm_pred_series is not None:\n",
    "    preds['lstm'] = lstm_pred_series\n",
    "model_cols = [c for c in preds.columns if c!='actual']\n",
    "if len(model_cols)>0:\n",
    "    preds['ensemble'] = preds[model_cols].mean(axis=1)\n",
    "    evaluate(preds['actual'], preds['ensemble'], label='Ensemble')\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(preds.index, preds['actual'], label='actual')\n",
    "    for c in model_cols:\n",
    "        plt.plot(preds.index, preds[c], alpha=0.6, label=c)\n",
    "    plt.plot(preds.index, preds['ensemble'], linewidth=2, label='ensemble')\n",
    "    plt.legend()\n",
    "    plt.title('Model comparisons')\n",
    "    plt.savefig('/content/outputs/model_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "# Save CSV\n",
    "preds.to_csv('/content/outputs/forecast_comparison.csv')\n",
    "print('Saved forecast table to /content/outputs/forecast_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c14ab71",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Next steps\n",
    "- Outputs saved under `/content/outputs` (plots + forecast CSV) and models under `/content/models`.\n",
    "- Next steps you might run:\n",
    "  - Increase LSTM epochs or tune hyperparameters\n",
    "  - Upload your real dataset and set DATA_PATH to use it\n",
    "  - Add additional regressors (price, holidays, marketing spend)\n",
    "\n",
    "Download the outputs folder as a zip (optional):\n",
    "```python\n",
    "!zip -r /content/outputs.zip /content/outputs\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
